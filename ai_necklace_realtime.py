#!/usr/bin/env python3
"""
AI Necklace Realtime - Raspberry Pi 5 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ

OpenAI Realtime APIã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åŒæ–¹å‘éŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ ã€‚
ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã„ã‚‹é–“ã ã‘éŸ³å£°å…¥åŠ›ã—ã€ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã§å¿œç­”ã‚’å¾—ã‚‹ã€‚

ãƒœã‚¿ãƒ³æ“ä½œ:
- ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ â†’ éŸ³å£°å…¥åŠ›é–‹å§‹ï¼ˆAIã®å¿œç­”ä¸­ãªã‚‰å‰²ã‚Šè¾¼ã¿ï¼‰
- ãƒœã‚¿ãƒ³ã‚’é›¢ã™ â†’ éŸ³å£°å…¥åŠ›çµ‚äº† â†’ AIå¿œç­”é–‹å§‹
"""

import os
import sys
import json
import base64
import asyncio
import threading
import signal
import time
from datetime import datetime

import numpy as np
import pyaudio
import websockets
from dotenv import load_dotenv

# GPIOãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    from gpiozero import Button
    GPIO_AVAILABLE = True
except ImportError:
    GPIO_AVAILABLE = False
    print("è­¦å‘Š: gpiozeroãŒä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰æ“ä½œãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™ã€‚")

# systemdã§å®Ÿè¡Œæ™‚ã«printå‡ºåŠ›ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§è¡¨ç¤ºã™ã‚‹ãŸã‚
sys.stdout.reconfigure(line_buffering=True)
sys.stderr.reconfigure(line_buffering=True)

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®š
CONFIG = {
    # Realtime APIè¨­å®š
    "model": "gpt-4o-realtime-preview-2024-12-17",
    "voice": "shimmer",  # alloy, echo, shimmer, etc.

    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªè¨­å®šï¼ˆRealtime APIã¯24kHz, 16bit PCM, ãƒ¢ãƒãƒ©ãƒ«ï¼‰
    "sample_rate": 24000,
    "channels": 1,
    "chunk_size": 1024,  # ç´„42ms @ 24kHz
    "output_sample_rate": 48000,  # USBã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ç”¨ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°

    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    "input_device_index": None,
    "output_device_index": None,

    # GPIOè¨­å®š
    "button_pin": 5,
    "use_button": True,

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    "instructions": """ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚
æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
éŸ³å£°ã§ã®ä¼šè©±ãªã®ã§ã€1-2æ–‡ç¨‹åº¦ã®çŸ­ã„å¿œç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
""",
}

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°
running = True
audio = None
button = None
ws_connection = None
is_speaking = False  # AIãŒè©±ã—ã¦ã„ã‚‹é–“ã¯True
is_recording = False  # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒéŒ²éŸ³ä¸­ã¯True
audio_output_buffer = []
audio_output_lock = threading.Lock()


def signal_handler(sig, frame):
    """Ctrl+C ã§çµ‚äº†"""
    global running
    print("\nçµ‚äº†ã—ã¾ã™...")
    running = False


def find_audio_device(p, device_type="input"):
    """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ã‚’è‡ªå‹•æ¤œå‡º"""
    target_names = ["USB PnP Sound", "USB Audio", "USB PnP Audio"]

    for i in range(p.get_device_count()):
        info = p.get_device_info_by_index(i)
        name = info.get("name", "")

        if device_type == "input" and info.get("maxInputChannels", 0) > 0:
            for target in target_names:
                if target in name:
                    print(f"å…¥åŠ›ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡º: [{i}] {name}")
                    return i
        elif device_type == "output" and info.get("maxOutputChannels", 0) > 0:
            for target in target_names:
                if target in name:
                    print(f"å‡ºåŠ›ãƒ‡ãƒã‚¤ã‚¹æ¤œå‡º: [{i}] {name}")
                    return i

    if device_type == "input":
        return p.get_default_input_device_info()["index"]
    else:
        return p.get_default_output_device_info()["index"]


def resample_audio(audio_data, from_rate, to_rate):
    """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚’ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""
    if from_rate == to_rate:
        return audio_data

    # int16ã®ãƒã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’numpyé…åˆ—ã«å¤‰æ›
    audio_array = np.frombuffer(audio_data, dtype=np.int16)

    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆç·šå½¢è£œé–“ï¼‰
    original_length = len(audio_array)
    target_length = int(original_length * to_rate / from_rate)
    indices = np.linspace(0, original_length - 1, target_length)
    resampled = np.interp(indices, np.arange(original_length), audio_array)

    return resampled.astype(np.int16).tobytes()


class RealtimeAudioHandler:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†ãƒãƒ³ãƒ‰ãƒ©"""

    def __init__(self):
        self.audio = pyaudio.PyAudio()
        self.input_stream = None
        self.output_stream = None
        self.is_recording = False
        self.is_playing = False
        self.output_buffer = []
        self.output_lock = threading.Lock()

    def start_input_stream(self):
        """ãƒã‚¤ã‚¯å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹å§‹"""
        input_device = CONFIG["input_device_index"]
        if input_device is None:
            input_device = find_audio_device(self.audio, "input")

        self.input_stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=CONFIG["channels"],
            rate=CONFIG["sample_rate"],
            input=True,
            input_device_index=input_device,
            frames_per_buffer=CONFIG["chunk_size"]
        )
        self.is_recording = True
        print("ğŸ¤ ãƒã‚¤ã‚¯å…¥åŠ›é–‹å§‹")

    def stop_input_stream(self):
        """ãƒã‚¤ã‚¯å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢"""
        if self.input_stream:
            self.is_recording = False
            self.input_stream.stop_stream()
            self.input_stream.close()
            self.input_stream = None
            print("ğŸ¤ ãƒã‚¤ã‚¯å…¥åŠ›åœæ­¢")

    def read_audio_chunk(self):
        """ãƒã‚¤ã‚¯ã‹ã‚‰éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’èª­ã¿å–ã‚Š"""
        if self.input_stream and self.is_recording:
            try:
                data = self.input_stream.read(CONFIG["chunk_size"], exception_on_overflow=False)
                return data
            except Exception as e:
                print(f"éŸ³å£°èª­ã¿å–ã‚Šã‚¨ãƒ©ãƒ¼: {e}")
        return None

    def start_output_stream(self):
        """ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹å§‹"""
        output_device = CONFIG["output_device_index"]
        if output_device is None:
            output_device = find_audio_device(self.audio, "output")

        self.output_stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=CONFIG["channels"],
            rate=CONFIG["output_sample_rate"],
            output=True,
            output_device_index=output_device,
            frames_per_buffer=CONFIG["chunk_size"] * 2
        )
        self.is_playing = True
        print("ğŸ”Š ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›é–‹å§‹")

    def stop_output_stream(self):
        """ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢"""
        if self.output_stream:
            self.is_playing = False
            self.output_stream.stop_stream()
            self.output_stream.close()
            self.output_stream = None
            print("ğŸ”Š ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼å‡ºåŠ›åœæ­¢")

    def play_audio_chunk(self, audio_data):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’å†ç”Ÿ"""
        if self.output_stream and self.is_playing:
            try:
                # 24kHz â†’ 48kHz ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                resampled = resample_audio(
                    audio_data,
                    CONFIG["sample_rate"],
                    CONFIG["output_sample_rate"]
                )
                self.output_stream.write(resampled)
            except Exception as e:
                print(f"éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")

    def add_to_output_buffer(self, audio_data):
        """å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã«éŸ³å£°ã‚’è¿½åŠ """
        with self.output_lock:
            self.output_buffer.append(audio_data)

    def clear_output_buffer(self):
        """å‡ºåŠ›ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢ï¼ˆå‰²ã‚Šè¾¼ã¿æ™‚ï¼‰"""
        with self.output_lock:
            self.output_buffer.clear()

    def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾"""
        self.stop_input_stream()
        self.stop_output_stream()
        if self.audio:
            self.audio.terminate()


class RealtimeClient:
    """OpenAI Realtime APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, audio_handler: RealtimeAudioHandler):
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

        self.audio_handler = audio_handler
        self.ws = None
        self.is_connected = False
        self.is_responding = False
        self.current_response_id = None

    async def connect(self):
        """WebSocketæ¥ç¶šã‚’ç¢ºç«‹"""
        url = f"wss://api.openai.com/v1/realtime?model={CONFIG['model']}"
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "OpenAI-Beta": "realtime=v1",
        }

        print(f"ğŸ”— Realtime APIã«æ¥ç¶šä¸­... ({CONFIG['model']})")

        self.ws = await websockets.connect(
            url,
            additional_headers=headers,
            ping_interval=20,
            ping_timeout=20,
        )
        self.is_connected = True
        print("âœ… Realtime APIæ¥ç¶šå®Œäº†")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é€ä¿¡
        await self.configure_session()

    async def configure_session(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã‚’é€ä¿¡"""
        session_config = {
            "type": "session.update",
            "session": {
                "modalities": ["text", "audio"],
                "instructions": CONFIG["instructions"],
                "voice": CONFIG["voice"],
                "input_audio_format": "pcm16",
                "output_audio_format": "pcm16",
                "input_audio_transcription": {
                    "model": "whisper-1"
                },
                "turn_detection": None,  # æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ï¼ˆãƒœã‚¿ãƒ³æ“ä½œï¼‰
            }
        }

        await self.ws.send(json.dumps(session_config))
        print("ğŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šå®Œäº†ï¼ˆæ‰‹å‹•ã‚¿ãƒ¼ãƒ³æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ï¼‰")

    async def send_audio_chunk(self, audio_data):
        """éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚’é€ä¿¡"""
        if not self.is_connected or not self.ws:
            return

        encoded = base64.b64encode(audio_data).decode("utf-8")
        message = {
            "type": "input_audio_buffer.append",
            "audio": encoded
        }
        await self.ws.send(json.dumps(message))

    async def commit_audio(self):
        """éŸ³å£°å…¥åŠ›ã‚’ç¢ºå®šã—ã¦å¿œç­”ã‚’è¦æ±‚"""
        if not self.is_connected or not self.ws:
            return

        # éŸ³å£°ãƒãƒƒãƒ•ã‚¡ã‚’ã‚³ãƒŸãƒƒãƒˆ
        await self.ws.send(json.dumps({"type": "input_audio_buffer.commit"}))

        # å¿œç­”ã‚’ç”Ÿæˆ
        await self.ws.send(json.dumps({"type": "response.create"}))
        print("ğŸ“¤ éŸ³å£°é€ä¿¡å®Œäº†ã€å¿œç­”å¾…ã¡...")

    async def cancel_response(self):
        """ç¾åœ¨ã®å¿œç­”ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ï¼ˆå‰²ã‚Šè¾¼ã¿ï¼‰"""
        if self.is_responding and self.ws:
            await self.ws.send(json.dumps({"type": "response.cancel"}))
            self.audio_handler.clear_output_buffer()
            print("âš¡ å¿œç­”ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ï¼ˆå‰²ã‚Šè¾¼ã¿ï¼‰")

    async def clear_input_buffer(self):
        """å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢"""
        if self.ws:
            await self.ws.send(json.dumps({"type": "input_audio_buffer.clear"}))

    async def receive_messages(self):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ã—ã¦å‡¦ç†"""
        try:
            async for message in self.ws:
                if not running:
                    break

                event = json.loads(message)
                await self.handle_event(event)

        except websockets.exceptions.ConnectionClosed:
            print("âš ï¸ WebSocketæ¥ç¶šãŒé–‰ã˜ã‚‰ã‚Œã¾ã—ãŸ")
            self.is_connected = False
        except Exception as e:
            print(f"âš ï¸ å—ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    async def handle_event(self, event):
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†"""
        event_type = event.get("type", "")

        if event_type == "session.created":
            print("ğŸ‰ ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†")

        elif event_type == "session.updated":
            print("ğŸ“ ã‚»ãƒƒã‚·ãƒ§ãƒ³æ›´æ–°å®Œäº†")

        elif event_type == "response.created":
            self.is_responding = True
            self.current_response_id = event.get("response", {}).get("id")

        elif event_type == "response.audio.delta":
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ä¿¡
            audio_b64 = event.get("delta", "")
            if audio_b64:
                audio_data = base64.b64decode(audio_b64)
                self.audio_handler.play_audio_chunk(audio_data)

        elif event_type == "response.audio_transcript.delta":
            # ãƒ†ã‚­ã‚¹ãƒˆãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            text = event.get("delta", "")
            if text:
                print(f"[AI] {text}", end="", flush=True)

        elif event_type == "response.audio_transcript.done":
            print()  # æ”¹è¡Œ

        elif event_type == "response.done":
            self.is_responding = False
            self.current_response_id = None
            print("âœ… å¿œç­”å®Œäº†")

        elif event_type == "input_audio_buffer.speech_started":
            print("ğŸ¤ éŸ³å£°æ¤œå‡ºé–‹å§‹")

        elif event_type == "input_audio_buffer.speech_stopped":
            print("ğŸ¤ éŸ³å£°æ¤œå‡ºçµ‚äº†")

        elif event_type == "conversation.item.input_audio_transcription.completed":
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç™ºè©±ã®ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
            transcript = event.get("transcript", "")
            if transcript:
                print(f"[ã‚ãªãŸ] {transcript}")

        elif event_type == "error":
            error = event.get("error", {})
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {error.get('message', 'Unknown error')}")

        elif event_type == "rate_limits.updated":
            pass  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®æ›´æ–°ã¯ç„¡è¦–

        else:
            # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šæœªå‡¦ç†ã®ã‚¤ãƒ™ãƒ³ãƒˆ
            # print(f"ğŸ“© ã‚¤ãƒ™ãƒ³ãƒˆ: {event_type}")
            pass

    async def disconnect(self):
        """æ¥ç¶šã‚’åˆ‡æ–­"""
        if self.ws:
            await self.ws.close()
            self.is_connected = False
            print("ğŸ”Œ Realtime APIåˆ‡æ–­")


async def audio_input_loop(client: RealtimeClient, audio_handler: RealtimeAudioHandler):
    """éŸ³å£°å…¥åŠ›ãƒ«ãƒ¼ãƒ—ï¼ˆãƒœã‚¿ãƒ³æŠ¼ä¸‹ä¸­ã®ã¿é€ä¿¡ï¼‰"""
    global running, button, is_recording

    while running:
        # ãƒœã‚¿ãƒ³æ“ä½œã‚’ç¢ºèª
        if CONFIG["use_button"] and button:
            if button.is_pressed:
                if not is_recording:
                    # éŒ²éŸ³é–‹å§‹
                    is_recording = True

                    # AIãŒè©±ã—ã¦ã„ãŸã‚‰å‰²ã‚Šè¾¼ã¿
                    if client.is_responding:
                        await client.cancel_response()

                    # å…¥åŠ›ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
                    await client.clear_input_buffer()

                    audio_handler.start_input_stream()

                # éŸ³å£°ã‚’èª­ã¿å–ã£ã¦é€ä¿¡
                chunk = audio_handler.read_audio_chunk()
                if chunk:
                    await client.send_audio_chunk(chunk)

            else:
                if is_recording:
                    # éŒ²éŸ³çµ‚äº†
                    is_recording = False
                    audio_handler.stop_input_stream()

                    # éŸ³å£°ã‚’ã‚³ãƒŸãƒƒãƒˆã—ã¦å¿œç­”ã‚’è¦æ±‚
                    await client.commit_audio()
        else:
            # ãƒœã‚¿ãƒ³ãªã—ãƒ¢ãƒ¼ãƒ‰ï¼ˆã‚­ãƒ¼ãƒœãƒ¼ãƒ‰å…¥åŠ›ã§ä»£æ›¿ï¼‰
            pass

        await asyncio.sleep(0.01)  # 10msé–“éš”


async def main_async():
    """éåŒæœŸãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—"""
    global running, button

    # ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒãƒ³ãƒ‰ãƒ©ã‚’åˆæœŸåŒ–
    audio_handler = RealtimeAudioHandler()

    # å‡ºåŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹å§‹
    audio_handler.start_output_stream()

    # Realtimeã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
    client = RealtimeClient(audio_handler)

    try:
        # æ¥ç¶š
        await client.connect()

        # å—ä¿¡ã‚¿ã‚¹ã‚¯ã¨å…¥åŠ›ã‚¿ã‚¹ã‚¯ã‚’ä¸¦è¡Œå®Ÿè¡Œ
        receive_task = asyncio.create_task(client.receive_messages())
        input_task = asyncio.create_task(audio_input_loop(client, audio_handler))

        print("\n" + "=" * 50)
        print("AI Necklace Realtime èµ·å‹•")
        print("=" * 50)
        if CONFIG["use_button"]:
            print(f"æ“ä½œæ–¹æ³•: GPIO{CONFIG['button_pin']}ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã„ã‚‹é–“è©±ã™")
        print("Ctrl+C ã§çµ‚äº†")
        print("=" * 50)
        print("\n--- ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„ ---\n")

        # çµ‚äº†ã‚’å¾…æ©Ÿ
        while running:
            await asyncio.sleep(0.1)

        # ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«
        receive_task.cancel()
        input_task.cancel()

        try:
            await receive_task
        except asyncio.CancelledError:
            pass

        try:
            await input_task
        except asyncio.CancelledError:
            pass

    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        await client.disconnect()
        audio_handler.cleanup()


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    global running, button

    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)

    # API ã‚­ãƒ¼ç¢ºèª
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print(".env ãƒ•ã‚¡ã‚¤ãƒ«ã« OPENAI_API_KEY=sk-... ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)

    # ãƒœã‚¿ãƒ³åˆæœŸåŒ–
    if CONFIG["use_button"] and GPIO_AVAILABLE:
        try:
            button = Button(CONFIG["button_pin"], pull_up=True, bounce_time=0.1)
            print(f"ãƒœã‚¿ãƒ³åˆæœŸåŒ–å®Œäº†: GPIO{CONFIG['button_pin']}")
        except Exception as e:
            print(f"ãƒœã‚¿ãƒ³åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            print("ãƒœã‚¿ãƒ³ãªã—ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
            button = None
            CONFIG["use_button"] = False
    else:
        button = None
        if CONFIG["use_button"]:
            print("GPIOãŒä½¿ç”¨ã§ããªã„ãŸã‚ã€ãƒœã‚¿ãƒ³ãªã—ãƒ¢ãƒ¼ãƒ‰ã§å‹•ä½œã—ã¾ã™")
            CONFIG["use_button"] = False

    # éåŒæœŸãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œ
    asyncio.run(main_async())

    print("çµ‚äº†ã—ã¾ã—ãŸ")


if __name__ == "__main__":
    main()
